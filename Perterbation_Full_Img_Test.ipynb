{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import vgg16, inception_v3\n",
    "\n",
    "#Load the Inception_V3 model\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd #import skimage\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "#fishpath =r'C:\\Users\\filepath\\bigimgFishFrog'\n",
    "images = [ PIL.Image.open(f) for f in glob(fishpath + '\\\\*.jpeg') ]\n",
    "def img2array(im):\n",
    "    if im.mode != 'RGB':\n",
    "        im = im.convert(mode='RGB')\n",
    "    return np.frombuffer(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n",
    "\n",
    "\n",
    "#now transpose images as they are read. \n",
    "TRAN_np_images = [ img2array(im.resize((299,299),resample=0).transpose(Image.TRANSPOSE)) for im in images ] #WHYYYYYY\n",
    "\n",
    "#normal images\n",
    "np_images = [ img2array(im.resize((299,299),resample=0)) for im in images ]\n",
    "\n",
    "####################################################################\n",
    "#filelist = glob(fishpath + '\\\\*.jpeg')\n",
    "#x = np.array([np.array(Image.open(fname)) for fname in filelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images #GIVES ARRAY DIMENSIONS? VECTORS? for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x #dont use this array of images this methodology does not work when using .resize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageNetFish = np_images.copy() \n",
    "ImageNetFish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img in ImageNetFish: \n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otherfishpath =r'C:\\Users\\filepath\\altfishbig'\n",
    "images2 = [ PIL.Image.open(f) for f in glob(otherfishpath + '\\\\*.jpg') ]\n",
    "\n",
    "def img2array(im):\n",
    "    if im.mode != 'RGB':\n",
    "        im = im.convert(mode='RGB')\n",
    "    return np.frombuffer(im.tobytes(), dtype='uint8').reshape((im.size[1], im.size[0], 3))\n",
    "\n",
    "#now transpose images as they are read. \n",
    "TRAN_np_images2 = [ img2array(im.resize((299,299),resample=0).transpose(Image.TRANSPOSE)) for im in images2 ]\n",
    "\n",
    "np_images2 = [ img2array(im.resize((299,299),resample=0)) for im in images2 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_images2 #GIVES ARRAY DIMENSIONS/VECTORS? for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img2 in np_images2:\n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img2)\n",
    "    plt.text(5, 5, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the PIL image to a numpy array\n",
    "# IN PIL - image is in (width, height, channel)\n",
    "# In Numpy - image is in (height, width, channel)\n",
    "#numpy_image = img_to_array(refish1)\n",
    "#plt.imshow(np.uint8(numpy_image))\n",
    "#plt.show()\n",
    "#print('numpy array size',numpy_image.shape)\n",
    "######################################################################\n",
    "# Convert the image / images into batch format\n",
    "# expand_dims will add an extra dimension to the data at a particular axis\n",
    "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "# Thus we add the extra dimension to the axis 0.\n",
    "for img in ImageNetFish:\n",
    "    image_batch1 = np.expand_dims(img, axis=0)\n",
    "    print('image batch size', image_batch1.shape)\n",
    "    plt.imshow(np.uint8(image_batch1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE NET IMAGES; ORIGINAL.\n",
    "n=0\n",
    "ImageNet = pd.DataFrame(columns = ['Original Accuracy'])\n",
    "processed_image1=[]\n",
    "predictions1=[]\n",
    "label1=[]\n",
    "for img in ImageNetFish:\n",
    "    n+=1\n",
    "    processed_image1 = inception_v3.preprocess_input(np.expand_dims(img, axis=0))\n",
    "    predictions1 = inception_model.predict(processed_image1)\n",
    "    label1 = decode_predictions(predictions1)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label1)\n",
    "    ImageNet.loc[n] = label1[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     plt.imshow(img)\n",
    "#     plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame\n",
    "PlainImageNet=ImageNet['Original Accuracy'].str[0]\n",
    "PlainImageNet\n",
    "df = PlainImageNet.str.split(\",\", n = 1, expand = True) #this is somehow needed.\n",
    "df = pd.DataFrame(ImageNet['Original Accuracy'].values.tolist(), index=df.index)\n",
    "df = df.drop([1,2,3,4], axis = 1)\n",
    "df = df.rename(columns={0: \"OriginalClassification\" })\n",
    "dfOrignalImageNet = pd.DataFrame(df)\n",
    "dfOrignalImageNet = pd.DataFrame(df['OriginalClassification'].values.tolist(), columns=['ID','Original Classification','Origianl Accuracy'])\n",
    "dfOrignalImageNet = dfOrignalImageNet.drop(['ID'], axis =1)\n",
    "dfOrignalImageNet\n",
    "#dfOrignalImageNet.to_csv(r'C:\\Users\\Filepath\\Image Net Original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the image / images into batch format\n",
    "# expand_dims will add an extra dimension to the data at a particular axis\n",
    "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "# Thus we add the extra dimension to the axis 0.\n",
    "\n",
    "for img2 in np_images2: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch2 = np.expand_dims(img2, axis=0)\n",
    "    print('image batch size', image_batch2.shape)\n",
    "    plt.imshow(np.uint8(image_batch2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER FISH DATA SET; ORIGNAL\n",
    "n=0\n",
    "AltFish = pd.DataFrame(columns = ['Original Accuracy'])\n",
    "for img2 in np_images2:\n",
    "    n+=1\n",
    "    processed_image2 = inception_v3.preprocess_input(np.expand_dims(img2, axis=0))\n",
    "    predictions2 = inception_model.predict(processed_image2)\n",
    "    label2 = decode_predictions(predictions2)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label2)\n",
    "    AltFish.loc[n] = label2[:1]\n",
    "    #DEBUGplt.figure()\n",
    "    #DEBUGplt.imshow(img2)\n",
    "    #DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlainAltFish=AltFish['Original Accuracy'].str[0]\n",
    "PlainAltFish\n",
    "df2 = pd.DataFrame\n",
    "df2 = PlainAltFish.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df2 = pd.DataFrame(AltFish['Original Accuracy'].values.tolist(), index=df2.index)\n",
    "df2 = df2.drop([1,2,3,4], axis = 1)\n",
    "df2 = df2.rename(columns={0: \"OriginalClassification\" })\n",
    "dfOrignalAltFish = pd.DataFrame(df2)\n",
    "dfOrignalAltFish = pd.DataFrame(df2['OriginalClassification'].values.tolist(), columns=['ID','Original Classification','Origianl Accuracy'])\n",
    "dfOrignalAltFish = dfOrignalAltFish.drop(['ID'], axis =1)\n",
    "dfOrignalAltFish\n",
    "#dfOrignalAltFish.to_csv(r'C:\\Users\\filepath\\Alternate Fish Original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpose images for ImgNet and other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img in TRAN_np_images: #check that the images are transposed\n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img2 in TRAN_np_images2:  #check that the images are transposed\n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img2)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IMAGENET IMAGES; TRANSPOSED\n",
    "for img in TRAN_np_images: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch3 = np.expand_dims(img, axis=0)\n",
    "    print('image batch size', image_batch3.shape)\n",
    "    plt.imshow(np.uint8(image_batch3[0]))\n",
    "    #DEBUG plt.figure()\n",
    "    #DEBUG plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE NET IMAGES; TRANSPOSED\n",
    "TRImageNet = pd.DataFrame(columns = ['Transpose Accuracy'])\n",
    "n=0\n",
    "for img in TRAN_np_images: #run through classifier.\n",
    "    n+=1\n",
    "    processed_image3 = inception_v3.preprocess_input(np.expand_dims(img, axis=0))\n",
    "    predictions3 = inception_model.predict(processed_image3)\n",
    "    label3 = decode_predictions(predictions3)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label3)\n",
    "    TRImageNet.loc[n] = label3[:1]\n",
    "    #DEBUGplt.figure()\n",
    "    #DEBUGplt.imshow(img)\n",
    "    #DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRANSImageNet=TRImageNet['Transpose Accuracy'].str[0]\n",
    "TRANSImageNet\n",
    "df3 = pd.DataFrame\n",
    "df3 = TRANSImageNet.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df3 = pd.DataFrame(TRImageNet['Transpose Accuracy'].values.tolist(), index=df3.index)\n",
    "df3 = df3.drop([1,2,3,4], axis = 1)\n",
    "df3 = df3.rename(columns={0: \"OriginalClassification\" })\n",
    "dfTRANSImageNet = pd.DataFrame(df3)\n",
    "dfTRANSImageNet = pd.DataFrame(df3['OriginalClassification'].values.tolist(), columns=['ID','Transposed Classification','Transpose Accuracy'])\n",
    "dfTRANSImageNet = dfTRANSImageNet.drop(['ID'], axis =1)\n",
    "dfTRANSImageNet\n",
    "#dfTRANSImageNet.to_csv(r'C:\\Users\\filepath\\Transposed Image Net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER FISH DATASET\n",
    "for img2 in TRAN_np_images2: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch4 = np.expand_dims(img2, axis=0)\n",
    "    print('image batch size', image_batch4.shape)\n",
    "    plt.imshow(np.uint8(image_batch4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "TRAltFish = pd.DataFrame(columns = ['Transpose Accuracy'])\n",
    "for img2 in TRAN_np_images2:\n",
    "    n+=1\n",
    "    processed_image4 = inception_v3.preprocess_input(np.expand_dims(img2, axis=0))\n",
    "    predictions4 = inception_model.predict(processed_image4)\n",
    "    label4 = decode_predictions(predictions4)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label4)\n",
    "    TRAltFish.loc[n] = label4[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     DEBUGplt.imshow(img2)\n",
    "#     DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRANSAltFish=TRAltFish['Transpose Accuracy'].str[0]\n",
    "TRANSAltFish\n",
    "df4 = pd.DataFrame\n",
    "df4 = TRANSAltFish.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df4 = pd.DataFrame(TRAltFish['Transpose Accuracy'].values.tolist(), index=df4.index)\n",
    "df4 = df4.drop([1,2,3,4], axis = 1)\n",
    "df4 = df4.rename(columns={0: \"OriginalClassification\" })\n",
    "dfTRANSAltFish = pd.DataFrame(df4)\n",
    "dfTRANSAltFish = pd.DataFrame(df4['OriginalClassification'].values.tolist(), columns=['ID','Transposed Classification','Transpose Accuracy'])\n",
    "dfTRANSAltFish = dfTRANSAltFish.drop(['ID'], axis =1)\n",
    "dfTRANSAltFish\n",
    "#dfTRANSAltFish.to_csv(r'C:\\Users\\filepath\\Transposed Alternate Fish.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian(Random) noise test....WIP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# out = np.zeros((26,26))\n",
    "# salt coordinates\n",
    "coords = [np.random.randint(0,26,50), np.random.randint(0,26,50)]\n",
    "\n",
    "# mask - 0 are regions where salt can be applied, otherwise don't touch\n",
    "mask = np.zeros(out.shape)\n",
    "mask[:13,:13] = 1\n",
    "mask[-13:,-13:] = 2\n",
    "\n",
    "# where does the salt coordinates land on the mask\n",
    "a = mask[coords]\n",
    "\n",
    "# find points where mask is 0\n",
    "b, = np.nonzero(a==0)\n",
    "\n",
    "# copy from coords only where mask is 0\n",
    "valid_coords = np.array(coords)[:,b]\n",
    "\n",
    "# apply salt on valid coordinates\n",
    "out[valid_coords.tolist()]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "row = 0\n",
    "col = 0\n",
    "ch = 0\n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\": #ROUND END RESULT?\n",
    "    \n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    \n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = (image.shape) #image.shape ######\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004 #0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    \n",
    "    #MODDED FUCNTION FOR DIRECTED NOISE AT IMAGE CORNERS\n",
    "    ##########################################################\n",
    "    elif noise_typ == \"s&pMIX\":\n",
    "        row,col,ch = (image.shape)\n",
    "        s_vs_p = .5 #.5\n",
    "        amount = .004 #0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        \n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))for i in image.shape]\n",
    "        # mask - 0 are regions where salt can be applied, otherwise don't touch\n",
    "        mask = np.zeros(image.shape)\n",
    "        mask[:100,:100] = 1\n",
    "        mask[-100:,-100:] = 2\n",
    "        mask[100:,-100:] = 3\n",
    "        mask[-100:,100:] = 4\n",
    "        \n",
    "        # where does the salt coordinates land on the mask\n",
    "        a = mask[coords]\n",
    "\n",
    "        # find points where mask is 0\n",
    "        b, = np.nonzero(a>0)\n",
    "\n",
    "        # copy from coords only where mask is 0\n",
    "        valid_coords = np.array(coords)[:,b]\n",
    "        \n",
    "        # apply salt on valid coordinates\n",
    "        out[valid_coords.tolist()]=1\n",
    "        #out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))for i in image.shape]\n",
    "        mask = np.zeros(image.shape)\n",
    "        mask[:100,:100] = 1\n",
    "        mask[-100:,-100:] = 2\n",
    "        mask[100:,-100:] = 3\n",
    "        mask[-100:,100:] = 4\n",
    "        \n",
    "        # where does the pepper coordinates land on the mask\n",
    "        a = mask[coords]\n",
    "\n",
    "        # find points where mask is 0\n",
    "        b, = np.nonzero(a>0)\n",
    "\n",
    "        # copy from coords only where mask is 0\n",
    "        valid_coords2 = np.array(coords)[:,b]\n",
    "        \n",
    "        # apply salt on valid coordinates\n",
    "        out[valid_coords2.tolist()]=0\n",
    "        #out[coords] = 0\n",
    "        return out\n",
    "    #####################################################################\n",
    "    \n",
    "    elif noise_typ == \"poisson\": #ROUND END RESULT?\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    \n",
    "    elif noise_typ ==\"speckle\": #ROUND END RESULT?\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images #Note: adding noise can either minisculey or drastically change original vectors/arrays!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = [ noisy(\"s&p\",(img2array(im.resize((299,299),resample=0)))) for im in images ]\n",
    "\n",
    "TempImageNetFish = np_images.copy()\n",
    "SaltyImageNetFish = np.array(TempImageNetFish)\n",
    "\n",
    "\n",
    "#\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
    "#Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaltyImageNetFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img in SaltyImageNetFish: \n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SALT AND PEP IMAGENET IMAGES\n",
    "for img in SaltyImageNetFish: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch5 = np.expand_dims(img, axis=0)\n",
    "    print('image batch size', image_batch5.shape)\n",
    "    plt.imshow(np.uint8(image_batch5[0]))\n",
    "    #DEBUG plt.figure()\n",
    "    #DEBUG plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SALT AND PEP IMAGENET IMAGES\n",
    "n=0\n",
    "NoiseImageNet = pd.DataFrame(columns = ['SaltNoise Accuracy'])\n",
    "for img in SaltyImageNetFish: #run through classifier.\n",
    "    n+=1\n",
    "    processed_image5 = inception_v3.preprocess_input(np.expand_dims(img, axis=0))\n",
    "    predictions5 = inception_model.predict(processed_image5)\n",
    "    label5 = decode_predictions(predictions5)\n",
    "    #print(\"Image #\", n)\n",
    "    #print (label5)\n",
    "    NoiseImageNet.loc[n] = label5[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     DEBUGplt.imshow(img)\n",
    "#     DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SaltImageNet = NoiseImageNet['SaltNoise Accuracy'].str[0]\n",
    "SaltImageNet\n",
    "df5 = pd.DataFrame\n",
    "df5 = SaltImageNet.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df5 = pd.DataFrame( NoiseImageNet['SaltNoise Accuracy'].values.tolist(), index=df5.index)\n",
    "df5 = df5.drop([1,2,3,4], axis = 1)\n",
    "df5 = df5.rename(columns={0: \"OriginalClassification\" })\n",
    "dfSaltImageNet = pd.DataFrame(df5)\n",
    "dfSaltImageNet = pd.DataFrame(df5['OriginalClassification'].values.tolist(), columns=['ID','SaltNoise Classification','Saltnoise Accuracy'])\n",
    "dfSaltImageNet = dfSaltImageNet.drop(['ID'], axis =1)\n",
    "dfSaltImageNet\n",
    "#dfSaltImageNet.to_csv(r'C:\\Users\\filepath\\SaltNoise Image Net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other fish data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images2 = [ noisy(\"s&p\",(img2array(im.resize((299,299),resample=0)))) for im in images2 ]\n",
    "TempOtherFish = np_images2.copy()\n",
    "OtherFish = np.array(TempOtherFish)\n",
    "#\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
    "#Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img2 in OtherFish: \n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img2)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SALT AND PEP OTHER FISH DATASET IMAGES\n",
    "for img2 in OtherFish: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch6 = np.expand_dims(img2, axis=0)\n",
    "    print('image batch size', image_batch6.shape)\n",
    "    plt.imshow(np.uint8(image_batch6[0]))\n",
    "    #DEBUG plt.figure()\n",
    "    #DEBUG plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SALT AND PEP OTHER FISH DATASET IMAGES\n",
    "n=0\n",
    "NoiseAltFish = pd.DataFrame(columns = ['SaltNoise Accuracy'])\n",
    "for img2 in OtherFish: #run through classifier.\n",
    "    n+=1\n",
    "    processed_image6 = inception_v3.preprocess_input(np.expand_dims(img2, axis=0))\n",
    "    predictions6 = inception_model.predict(processed_image6)\n",
    "    label6 = decode_predictions(predictions6)\n",
    "    #print(\"Image #\", n)\n",
    "    #print (label6)\n",
    "    NoiseAltFish.loc[n] = label6[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     DEBUGplt.imshow(img2)\n",
    "#     DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SaltAltFish = NoiseAltFish['SaltNoise Accuracy'].str[0]\n",
    "SaltAltFish\n",
    "df6 = pd.DataFrame\n",
    "df6 = SaltAltFish.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df6 = pd.DataFrame(NoiseAltFish['SaltNoise Accuracy'].values.tolist(), index=df6.index)\n",
    "df6 = df6.drop([1,2,3,4], axis = 1)\n",
    "df6 = df6.rename(columns={0: \"OriginalClassification\" })\n",
    "dfSaltAltFish = pd.DataFrame(df6)\n",
    "dfSaltAltFish = pd.DataFrame(df6['OriginalClassification'].values.tolist(), columns=['ID','SaltNoise Classification','Saltnoise Accuracy'])\n",
    "dfSaltAltFish = dfSaltAltFish.drop(['ID'], axis =1)\n",
    "dfSaltAltFish\n",
    "#dfSaltAltFish.to_csv(r'C:\\Users\\filepath\\SaltNoise Alternate Fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directed Noise Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = [ noisy(\"s&pMIX\",(img2array(im.resize((299,299),resample=0)))) for im in images ]\n",
    "\n",
    "TempImageNetFish = np_images.copy()\n",
    "SaltyDirectINetFish = np.array(TempImageNetFish)\n",
    "#\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
    "#Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaltyDirectINetFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img in SaltyDirectINetFish: \n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#*MIXED* SALT AND PEP IMAGENET IMAGES\n",
    "for img in SaltyDirectINetFish: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch7 = np.expand_dims(img, axis=0)\n",
    "    print('image batch size', image_batch7.shape)\n",
    "    plt.imshow(np.uint8(image_batch7[0]))\n",
    "    #DEBUG plt.figure()\n",
    "    #DEBUG plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "MIXEDNoiseImageNet = pd.DataFrame(columns = ['MixNoise Accuracy'])\n",
    "for img in SaltyDirectINetFish: #run through classifier.\n",
    "    n+=1\n",
    "    processed_image7 = inception_v3.preprocess_input(np.expand_dims(img, axis=0))\n",
    "    predictions7 = inception_model.predict(processed_image7)\n",
    "    label7 = decode_predictions(predictions7)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label7)\n",
    "    MIXEDNoiseImageNet.loc[n] = label7[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     DEBUGplt.imshow(img)\n",
    "#     DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MIXSaltImageNet = MIXEDNoiseImageNet['MixNoise Accuracy'].str[0]\n",
    "MIXSaltImageNet\n",
    "df7 = pd.DataFrame\n",
    "df7 = MIXSaltImageNet.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df7 = pd.DataFrame(MIXEDNoiseImageNet['MixNoise Accuracy'].values.tolist(), index=df7.index)\n",
    "df7 = df7.drop([1,2,3,4], axis = 1)\n",
    "df7 = df7.rename(columns={0: \"OriginalClassification\" })\n",
    "dfMIXSaltImageNet = pd.DataFrame(df7)\n",
    "dfMIXSaltImageNet = pd.DataFrame(df7['OriginalClassification'].values.tolist(), columns=['ID','DIRSaltNoise Classification','DIRSaltnoise Accuracy'])\n",
    "dfMIXSaltImageNet = dfMIXSaltImageNet.drop(['ID'], axis =1)\n",
    "dfMIXSaltImageNet\n",
    "#dfMIXSaltImageNet.to_csv(r'C:\\Users\\filepath\\DirectedNoise Image Net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images2 = [ noisy(\"s&pMIX\",(img2array(im.resize((299,299),resample=0)))) for im in images2 ]\n",
    "\n",
    "TempAltFish = np_images2.copy()\n",
    "SaltyDirectAltFish = np.array(TempAltFish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaltyDirectAltFish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for img2 in SaltyDirectAltFish: \n",
    "    n+=1\n",
    "    plt.figure()\n",
    "    plt.imshow(img2)\n",
    "    plt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#*MIXED* SALT AND PEP ALT IMAGES\n",
    "for img in SaltyDirectAltFish: #load batch files; check proper dimensions for Inception_V3 model\n",
    "    image_batch8 = np.expand_dims(img, axis=0)\n",
    "    print('image batch size', image_batch8.shape)\n",
    "    plt.imshow(np.uint8(image_batch8[0]))\n",
    "    #DEBUG plt.figure()\n",
    "    #DEBUG plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "MIXEDNoiseAltFish = pd.DataFrame(columns = ['MixNoise Accuracy'])\n",
    "for img in SaltyDirectAltFish: #run through classifier.\n",
    "    n+=1\n",
    "    processed_image8 = inception_v3.preprocess_input(np.expand_dims(img, axis=0))\n",
    "    predictions8 = inception_model.predict(processed_image8)\n",
    "    label8 = decode_predictions(predictions8)\n",
    "    print(\"Image #\", n)\n",
    "    #print (label8)\n",
    "    MIXEDNoiseAltFish.loc[n] = label8[:1]\n",
    "#     DEBUGplt.figure()\n",
    "#     DEBUGplt.imshow(img2)\n",
    "#     DEBUGplt.text(4, 4, n, bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MIXSaltAltFish = MIXEDNoiseAltFish['MixNoise Accuracy'].str[0]\n",
    "MIXSaltAltFish\n",
    "df8 = pd.DataFrame\n",
    "df8 = MIXSaltAltFish.str.split(\",\", n = 1, expand = True) #this is somehow needed. \n",
    "df8 = pd.DataFrame(MIXEDNoiseAltFish['MixNoise Accuracy'].values.tolist(), index=df8.index)\n",
    "df8 = df8.drop([1,2,3,4], axis = 1)\n",
    "df8 = df8.rename(columns={0: \"OriginalClassification\" })\n",
    "dfMIXSaltAltFish = pd.DataFrame(df8)\n",
    "dfMIXSaltAltFish = pd.DataFrame(df8['OriginalClassification'].values.tolist(), columns=['ID',\"DIRSaltNoise Classification(ALT)\",\"DIRSaltnoise Accuracy(ALT)\"])\n",
    "dfMIXSaltAltFish = dfMIXSaltAltFish.drop(['ID'], axis =1)\n",
    "dfMIXSaltAltFish\n",
    "#dfMIXSaltAltFish.to_csv(r'C:\\Users\\filepath\\DirectedNoise Alt Fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfSaltImageNet=dfSaltImageNet.astype(str)\n",
    "#dfMIXSaltImageNet=dfMIXSaltImageNet.astype(str)\n",
    "\n",
    "CompareImgNetNoises = dfSaltImageNet.join(dfMIXSaltImageNet)\n",
    "#CompareImgNetNoises.to_csv(r'C:\\Users\\fielpath\\Img Net Fish Noise Comparision.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CompareAltFishNoises =dfSaltAltFish.join(dfMIXSaltAltFish)\n",
    "CompareAltFishNoises\n",
    "#CompareAltFishNoises.to_csv(r'C:\\Users\\filepath\\Alt Fish Noise Comparision.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
